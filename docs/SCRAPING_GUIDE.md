# ğŸ† GuÃ­a Completa: Scraping de Datos Deportivos

## ğŸ“‹ Ãndice
1. [Fuentes Recomendadas](#fuentes-recomendadas)
2. [Aspectos Legales](#aspectos-legales)
3. [ImplementaciÃ³n TÃ©cnica](#implementaciÃ³n-tÃ©cnica)
4. [Comparativa de Fuentes](#comparativa-de-fuentes)
5. [Mejores PrÃ¡cticas](#mejores-prÃ¡cticas)

---

## ğŸ¯ Fuentes Recomendadas

### âœ… TIER 1: APIs Oficiales (Recomendado)

#### 1. **Football-Data.co.uk** (Ya implementado)
- **URL**: https://www.football-data.co.uk/
- **MÃ©todo**: Descarga directa HTTP (CSV)
- **Costo**: ğŸ†“ 100% Gratuito
- **Legalidad**: âœ… Completamente legal
- **Datos**:
  - Top-20 ligas europeas
  - Resultados histÃ³ricos desde 1993
  - Odds de apertura y cierre (Bet365, Pinnacle)
  - ActualizaciÃ³n: Semanal

**ImplementaciÃ³n actual:**
```bash
make fd  # Descarga automÃ¡tica
```

---

#### 2. **API-FOOTBALL (RapidAPI)** (Ya implementado)
- **URL**: https://rapidapi.com/api-sports/api/api-football
- **MÃ©todo**: API REST
- **Costo**: 
  - ğŸ†“ Gratis: 100 req/dÃ­a
  - ğŸ’° Pro: $30/mes (3,000 req/dÃ­a)
- **Legalidad**: âœ… Completamente legal
- **Datos**:
  - 1000+ ligas (incluye LATAM)
  - Fixtures en tiempo real
  - Odds de mÃºltiples casas
  - EstadÃ­sticas de equipos/jugadores

**ImplementaciÃ³n actual:**
```bash
# Configurar en .env:
# API_FOOTBALL_KEY=tu_clave

make dimayor_api  # Colombia
```

---

#### 3. **The Odds API** (MÃ³dulo creado)
- **URL**: https://the-odds-api.com/
- **MÃ©todo**: API REST
- **Costo**:
  - ğŸ†“ Gratis: 500 req/mes (solo odds actuales)
  - ğŸ’° Starter: $50/mes (histÃ³ricos limitados)
  - ğŸ’° Pro: $200+/mes (histÃ³ricos completos)
- **Legalidad**: âœ… Completamente legal
- **Datos**:
  - Odds actuales de 50+ casas
  - Snapshots histÃ³ricos (plan pago)
  - Pinnacle, Bet365, Betfair, etc.
  - Closing odds para CLV

**Uso:**
```python
from src.etl.the_odds_api import get_odds

# Configurar THE_ODDS_API_KEY en .env
odds = get_odds("soccer_england_epl", markets="h2h")
```

---

### âš ï¸ TIER 2: Scraping Tolerado (Educativo/Personal)

#### 4. **FBref** (NUEVO - Implementado)
- **URL**: https://fbref.com/
- **MÃ©todo**: Web Scraping (pandas.read_html)
- **Costo**: ğŸ†“ Gratis
- **Legalidad**: âœ… Permitido con rate limiting
- **Rate Limit**: 15-20 requests/minuto
- **Datos**:
  - EstadÃ­sticas avanzadas (xG, xA, presiÃ³n)
  - 100+ ligas desde 2017
  - Datos de jugadores y equipos
  - MÃ©tricas de pases, defensivas, tiros

**Uso:**
```bash
# Temporada actual (Top-5)
make fbref

# Temporada especÃ­fica
python -m src.etl.fbref_scraper --leagues EPL --season 2023-2024

# Todas las ligas disponibles
python -m src.etl.fbref_scraper --leagues EPL La_Liga Bundesliga Serie_A Ligue_1
```

**Datos descargados:**
- `data/raw/fbref/EPL_latest_table.csv` - Tabla de posiciones
- `data/raw/fbref/EPL_latest_shooting.csv` - EstadÃ­sticas de tiros
- `data/raw/fbref/EPL_latest_passing.csv` - EstadÃ­sticas de pases
- `data/raw/fbref/EPL_latest_defense.csv` - EstadÃ­sticas defensivas
- `data/raw/fbref/EPL_latest_full.csv` - Todo merged

**TÃ©rminos de uso:**
- Sports Reference (dueÃ±o de FBref) permite scraping educativo
- Ver: https://www.sports-reference.com/bot-traffic.html
- Requisitos:
  - Rate limiting obligatorio (<20 req/min)
  - User-Agent identificable
  - No comercial sin permiso

---

#### 5. **Understat** (Ya implementado)
- **URL**: https://understat.com/
- **MÃ©todo**: Web Scraping (JSON embebido)
- **Costo**: ğŸ†“ Gratis
- **Legalidad**: âš ï¸ Zona gris (tolerado para uso personal)
- **Datos**:
  - xG (Expected Goals) por partido
  - Top-5 ligas europeas
  - Datos de jugadores
  - Shots + xG map

**Uso:**
```bash
make understat
```

**Consideraciones:**
- Scraping NO oficialmente permitido
- Usa rate limiting (0.4s delay)
- Solo uso personal/educativo
- Puede cambiar estructura HTML

---

#### 6. **Transfermarkt**
- **URL**: https://www.transfermarkt.com/
- **MÃ©todo**: Web Scraping (Selenium requerido)
- **Costo**: ğŸ†“ Gratis
- **Legalidad**: âŒ Contra Terms of Service
- **Datos**:
  - Valuaciones de jugadores
  - Transferencias histÃ³ricas
  - 600+ ligas
  - Plantillas completas

**DesafÃ­os tÃ©cnicos:**
- Cloudflare agresivo
- Requiere Selenium/Playwright
- Bloqueos de IP frecuentes
- Requiere proxy rotation

**NO IMPLEMENTADO** - Alto riesgo de bloqueo

---

### ğŸ’ TIER 3: APIs Profesionales (Enterprise)

#### 7. **Stats Perform (Opta)**
- **URL**: https://www.statsperform.com/
- **Costo**: ğŸ’ $500-5,000/mes (empresa)
- **Datos**: Oficiales de 60+ ligas (usado por ESPN, BBC)

#### 8. **Sportradar**
- **URL**: https://sportradar.com/
- **Costo**: ğŸ’ Enterprise (contactar ventas)
- **Datos**: Partner oficial FIFA/UEFA

#### 9. **SportsDataIO**
- **URL**: https://sportsdata.io/
- **Costo**: ğŸ’° $50-500/mes
- **Datos**: NFL, NBA, MLB, NHL, Soccer

---

## âš–ï¸ Aspectos Legales

### âœ… **Permitido Legalmente**
1. **APIs oficiales con clave** (API-FOOTBALL, The Odds API)
2. **Descargas directas HTTP** (Football-Data)
3. **Scraping con permiso explÃ­cito** (FBref educativo)
4. **Datos pÃºblicos sin ToS restrictivos**

### âš ï¸ **Zona Gris**
1. **Scraping de sitios que no prohÃ­ben explÃ­citamente** (Understat)
2. **Uso personal/educativo de datos pÃºblicos**
3. **Scraping con rate limiting respetuoso**

**RecomendaciÃ³n:** OK para proyectos personales/educativos. NO redistribuir.

### âŒ **Prohibido / Alto Riesgo**
1. **Scraping contra Terms of Service** (Transfermarkt)
2. **Burlar medidas anti-bot** (Cloudflare bypass)
3. **Uso comercial de datos scraped sin permiso**
4. **Rate limiting agresivo (DoS)**

---

## ğŸ› ï¸ ImplementaciÃ³n TÃ©cnica

### Rate Limiting (CRÃTICO)

#### OpciÃ³n 1: Sleep manual
```python
import time

time.sleep(3)  # 3 segundos entre requests
response = requests.get(url)
```

#### OpciÃ³n 2: Decorator de rate limiting
```python
from ratelimit import limits, sleep_and_retry

@sleep_and_retry
@limits(calls=15, period=60)  # 15 calls por minuto
def fetch_data(url):
    return requests.get(url)
```

#### OpciÃ³n 3: Backoff exponencial
```python
import backoff

@backoff.on_exception(backoff.expo, requests.exceptions.RequestException, max_tries=3)
def fetch_with_retry(url):
    return requests.get(url)
```

---

### User-Agent (IMPORTANTE)

```python
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': 'text/html,application/xhtml+xml',
    'Accept-Language': 'en-US,en;q=0.9',
}

response = requests.get(url, headers=headers)
```

---

### Manejo de Errores

```python
def safe_scrape(url, max_retries=3):
    for i in range(max_retries):
        try:
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            return response
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 429:  # Too Many Requests
                wait_time = 2 ** i * 60  # Exponential backoff
                print(f"Rate limited. Esperando {wait_time}s...")
                time.sleep(wait_time)
            elif e.response.status_code == 403:  # Forbidden
                print("âŒ Bloqueado. Considera usar proxy.")
                break
            else:
                raise
        except requests.exceptions.Timeout:
            print(f"â±ï¸ Timeout. Reintento {i+1}/{max_retries}")
            time.sleep(5)
    return None
```

---

### Proxy Rotation (Para sitios restrictivos)

```python
import random

PROXIES = [
    'http://proxy1.com:8080',
    'http://proxy2.com:8080',
    'http://proxy3.com:8080',
]

def get_with_proxy(url):
    proxy = random.choice(PROXIES)
    proxies = {'http': proxy, 'https': proxy}
    return requests.get(url, proxies=proxies)
```

---

## ğŸ“Š Comparativa de Fuentes

| Fuente | MÃ©todo | Costo | Legalidad | Dificultad | Calidad | Rate Limit |
|--------|--------|-------|-----------|------------|---------|------------|
| **Football-Data** | HTTP | ğŸ†“ | âœ… Legal | â­ | â­â­â­â­â­ | Sin lÃ­mite |
| **FBref** | Scraping | ğŸ†“ | âœ… Permitido | â­â­ | â­â­â­â­â­ | 20/min |
| **Understat** | Scraping | ğŸ†“ | âš ï¸ Gris | â­â­ | â­â­â­â­â­ | Manual |
| **API-FOOTBALL** | API | $30/mes | âœ… Legal | â­ | â­â­â­â­ | 100/dÃ­a gratis |
| **The Odds API** | API | $50/mes | âœ… Legal | â­ | â­â­â­â­â­ | 500/mes gratis |
| **Transfermarkt** | Scraping | ğŸ†“ | âŒ Prohibido | â­â­â­â­ | â­â­â­â­ | Cloudflare |
| **Sportradar** | API | $1K+/mes | âœ… Legal | â­ | â­â­â­â­â­ | Alto |

---

## ğŸ“ Mejores PrÃ¡cticas

### 1. **JerarquÃ­a de DecisiÃ³n**
```
Â¿Hay API oficial? â†’ Ãšsala (siempre preferible)
  â†“ NO
Â¿Los Terms permiten scraping? â†’ Scrape con rate limiting
  â†“ NO
Â¿Es zona gris? â†’ Solo uso personal + rate limiting conservador
  â†“ NO
âŒ NO scrapear (riesgo legal/tÃ©cnico alto)
```

### 2. **Rate Limiting Recomendado**

| Tipo de Sitio | Delay Recomendado |
|--------------|-------------------|
| APIs oficiales | SegÃºn documentaciÃ³n |
| Sitios que permiten scraping | 3-5 segundos |
| Zona gris | 5-10 segundos |
| Sitios restrictivos | 10-30 segundos + proxy |

### 3. **Almacenamiento en CachÃ©**
```python
import pickle
from pathlib import Path

def get_cached_or_fetch(url, cache_file, max_age_hours=24):
    cache = Path(cache_file)
    if cache.exists():
        age = time.time() - cache.stat().st_mtime
        if age < max_age_hours * 3600:
            return pickle.load(cache.open('rb'))
    
    data = fetch_data(url)
    pickle.dump(data, cache.open('wb'))
    return data
```

### 4. **Respeta robots.txt**
```python
from urllib.robotparser import RobotFileParser

def can_scrape(url):
    rp = RobotFileParser()
    rp.set_url(f"{url}/robots.txt")
    rp.read()
    return rp.can_fetch("*", url)
```

### 5. **Logging y Monitoreo**
```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('scraping.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

logger.info(f"Scraping {url}")
logger.warning(f"Rate limited en {url}")
logger.error(f"Error scraping {url}: {e}")
```

---

## ğŸš€ RecomendaciÃ³n para tu Proyecto

### **Setup Actual (Ã“ptimo para empezar):**
```bash
# 1. Top-5 Ligas Europeas (GRATIS, LEGAL)
make all_fd

# 2. xG metrics (GRATIS, uso educativo)
make understat

# 3. EstadÃ­sticas avanzadas (GRATIS, LEGAL) [NUEVO]
make fbref

# 4. Dashboard
make dashboard
```

### **Upgrade Recomendado ($30-50/mes):**
```bash
# En .env:
API_FOOTBALL_KEY=...  # $30/mes para LATAM
THE_ODDS_API_KEY=...  # $50/mes para closing odds

# Ejecutar:
make all_dimayor  # Colombia
make clv          # Closing Line Value
make alerts       # Picks de valor
```

---

## ğŸ“š Recursos Adicionales

### LibrerÃ­as Ãštiles
```bash
pip install requests beautifulsoup4 lxml
pip install ratelimit backoff
pip install selenium playwright  # Para sitios JS-heavy
pip install pandas  # Para read_html directo
```

### DocumentaciÃ³n
- FBref ToS: https://www.sports-reference.com/bot-traffic.html
- robots.txt spec: https://developers.google.com/search/docs/advanced/robots/intro
- HTTP status codes: https://httpstatuses.com/

### Comunidades
- r/webscraping (Reddit)
- Stack Overflow [web-scraping tag]
- GitHub Topics: #sports-data #web-scraping

---

## âš ï¸ Disclaimer Legal

Este proyecto es para **uso educativo/personal Ãºnicamente**. 

- **NO redistribuir datos scraped comercialmente**
- **Respetar Terms of Service de cada sitio**
- **Usar rate limiting apropiado**
- **Atribuir fuentes en anÃ¡lisis pÃºblicos**

El autor no se hace responsable del uso indebido de estas herramientas.

---

**Ãšltima actualizaciÃ³n**: Octubre 2025  
**Mantenedor**: Sports Forecasting PRO

